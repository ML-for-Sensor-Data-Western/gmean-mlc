# Any-Class Presence Likelihood for Robust Multi-Label Classification with Abundant Negative Data

This repository is the official implementation of the **📄 Paper:** [Any-Class Presence Likelihood for Robust Multi-Label Classification with Abundant Negative Data](https://arxiv.org/abs/2506.05721)

## Overview

This project introduces a novel auxiliary loss function designed to enhance multi-label classification (MLC) tasks, particularly in scenarios with a large number of negative samples (data points not belonging to any defined class). The auxiliary loss acts as a complementary term to standard MLC loss functions.

## Features

* Implementation of a novel auxiliary loss term for MLC.
* Focus on improving performance in the presence of many negative samples.
* Modular structure using PyTorch Lightning.

## Project Structure

```
.
├── data_scripts/       # Scripts for data downloading and preprocessing
├── gmean_mlc/          # Core PyTorch code: datasets, dataloaders, models, lightning modules, metrics
├── likelihood_simulation/  # probability and likeliood surface visualiation demo
├── scripts/            # Main executable scripts for training, inference, etc.
```

## Setup

**Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

   **Note:** TresNet models require the `inplace_abn` dependency. If `inplace_abn` installation fails, please refer to the installation instructions at: https://github.com/mapillary/inplace_abn

## Data Preparation

The scripts required for downloading and preparing the datasets used in this project are located in the `data_scripts/` directory. Please refer to the specific scripts within that directory for instructions on how to prepare your data.

The PyTorch `Dataset` and `LightningDataModule` implementations can be found in the `gmean_mlc/` directory.

## Usage

The primary scripts for running experiments are located in the `scripts/` directory.

* **Training (`scripts/lightning_trainer.py`):** This script handles model training using PyTorch Lightning.

  *Example command:*

  ```bash
  python scripts/lightning_trainer.py \
      --dataset coco \
      --wandb_project gmean-mlc-coco \
      --ann_root /path/to/coco-2017/annotations/ \
      --data_root /path/to/coco-2017/images/ \
      --workers 8 \
      --log_save_dir /path/to/training_logs/ \
      --precision 16-mixed \
      --matmul_precision high \
      --model maxvit_s \
      --max_epochs 90 \
      --optimizer_type adamW \
      --learning_rate 1e-3 \
      --min_lr 1e-5 \
      --warmup_steps 5 \
      --warmup_start_factor 0.01 \
      --weight_decay 0.05 \
      --base_loss focal \
      --class_balancing_beta 0.9999 \
      --meta_loss_weight 1 \
      --meta_loss_beta 0.02 \
      --gpus 0 1 \
      --log_version <your_log_version> # e.g., 256
  ```
* **Inference (`scripts/inference.py`):** Loads trained model checkpoints and performs inference on a specified data split (e.g., validation or test set). It saves the raw model outputs (scores/predictions) to CSV files.

  *Example command:*

  ```bash
  python scripts/inference.py \
      --dataset coco \
      --ann_root /path/to/coco-2017/annotations/ \
      --data_root /path/to/coco-2017/images/ \
      --batch_size 256 \
      --log_dir /path/to/coco-2017/training_logs/ \
      --versions <log_version_1> <log_version_2> ... # e.g., 100 101 102 \
      --results_output results/results-coco \
      --split Val \
      --device_id 0
  ```

  *Note: Replace `<log_version_1>` etc. with the actual log versions generated during training.*
* **Result Calculation (`scripts/calculate_results.py`):** Takes the CSV output files generated by `scripts/inference.py` and the corresponding annotations to calculate evaluation metrics.

  *Example command:*

  ```bash
  python scripts/calculate_results.py \
      --dataset coco \
      --ann_root /path/to/coco-2017/annotations/ \
      --data_root /path/to/coco-2017/images/all_images/ \
      --split Val \
      --score_dir results/results-coco/ \
      --versions <log_version_1> <log_version_2> ... # e.g., 100 101 102
  ```

  *Note: The `--version` arguments should correspond to the log versions for which inference was run.*

*Please consult the individual scripts for a full list of arguments and their descriptions (e.g., using `python scripts/lightning_trainer.py --help`).*

## Results

The `results/` directory is used to store the outputs generated by `scripts/inference.py` and `scripts/calculate_results.py`. This directory is included in `.gitignore` and is not tracked by version control.

### Performance Metrics

#### SewerML Dataset
Performance metrics for SewerML dataset. The test benchmark only provided F2-CIW and F1-Neg.

<table>
<thead>
  <tr>
    <th rowspan="2">Model</th>
    <th rowspan="2">Loss</th>
    <th colspan="4"><strong>Validation</strong></th>
    <th colspan="2"><strong>Test</strong></th>
  </tr>
  <tr>
    <th>F1</th>
    <th>F2-CIW</th>
    <th>mAP</th>
    <th>F1-Neg</th>
    <th>F2-CIW</th>
    <th>F1-Neg</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><strong>TresNet-L</strong></td>
    <td>J<sup>cb</sup><sub>bce</sub></td>
    <td>63.13</td>
    <td>61.96</td>
    <td>65.63</td>
    <td>91.9</td>
    <td>60.02</td>
    <td><strong>91.58</strong></td>
  </tr>
  <tr>
    <td>(53.6M)</td>
    <td>J<sup>cb</sup><sub>any|bce</sub></td>
    <td><strong>64.23</strong></td>
    <td><strong>65.1</strong></td>
    <td><strong>66.86</strong></td>
    <td><strong>91.95</strong></td>
    <td><strong>64.16</strong></td>
    <td>91.35</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>focal</sub></td>
    <td>59.73</td>
    <td>57.66</td>
    <td>62.71</td>
    <td>91.21</td>
    <td>56.08</td>
    <td>90.99</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>any|focal</sub></td>
    <td>63.33</td>
    <td>64.22</td>
    <td>65.82</td>
    <td>91.59</td>
    <td>62.99</td>
    <td>91.05</td>
  </tr>
  <tr>
    <td><strong>ViT-B16</strong></td>
    <td>J<sup>cb</sup><sub>bce</sub></td>
    <td>48.25</td>
    <td>45.67</td>
    <td>52</td>
    <td>89.55</td>
    <td>44.39</td>
    <td>88.85</td>
  </tr>
  <tr>
    <td>(85.8M)</td>
    <td>J<sup>cb</sup><sub>any|bce</sub></td>
    <td>52.03</td>
    <td>52.61</td>
    <td>53.15</td>
    <td>89.62</td>
    <td>50.49</td>
    <td>88.9</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>focal</sub></td>
    <td>51.85</td>
    <td>51.28</td>
    <td>54.09</td>
    <td><strong>89.95</strong></td>
    <td>48.6</td>
    <td><strong>89.44</strong></td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>any|focal</sub></td>
    <td><strong>52.63</strong></td>
    <td><strong>54.58</strong></td>
    <td><strong>54.35</strong></td>
    <td>89.14</td>
    <td><strong>52.25</strong></td>
    <td>88.35</td>
  </tr>
  <tr>
    <td><strong>MaxViT-S</strong></td>
    <td>J<sup>cb</sup><sub>bce</sub></td>
    <td>66.99</td>
    <td>67.15</td>
    <td>69.47</td>
    <td><strong>93.34</strong></td>
    <td>65.64</td>
    <td><strong>92.83</strong></td>
  </tr>
  <tr>
    <td>(68.2M)</td>
    <td>J<sup>cb</sup><sub>any|bce</sub></td>
    <td>67.05</td>
    <td>68.16</td>
    <td><strong>70.23</strong></td>
    <td>92.96</td>
    <td>66.73</td>
    <td>92.46</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>focal</sub></td>
    <td>66.18</td>
    <td>66.51</td>
    <td>69.42</td>
    <td>92.96</td>
    <td>65.28</td>
    <td>92.48</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>any|focal</sub></td>
    <td><strong>67.45</strong></td>
    <td><strong>69.04</strong></td>
    <td>70.18</td>
    <td>93.15</td>
    <td><strong>67.41</strong></td>
    <td>92.58</td>
  </tr>
</tbody>
</table>

#### ChestX-ray14 Dataset
Performance metrics for ChestX-ray14 dataset.

<table>
<thead>
  <tr>
    <th rowspan="2">Model</th>
    <th rowspan="2">Loss</th>
    <th colspan="4"><strong>Validation</strong></th>
    <th colspan="4"><strong>Test</strong></th>
  </tr>
  <tr>
    <th>F1</th>
    <th>F2</th>
    <th>mAP</th>
    <th>F1-Neg</th>
    <th>F1</th>
    <th>F2</th>
    <th>mAP</th>
    <th>F1-Neg</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><strong>TresNet-L</strong></td>
    <td>J<sup>cb</sup><sub>bce</sub></td>
    <td>13.98</td>
    <td>12.77</td>
    <td>17.55</td>
    <td><strong>72.83</strong></td>
    <td>14.63</td>
    <td>13.02</td>
    <td>18.57</td>
    <td><strong>72.45</strong></td>
  </tr>
  <tr>
    <td>(53.6M)</td>
    <td>J<sup>cb</sup><sub>any|bce</sub></td>
    <td><strong>19.99</strong></td>
    <td><strong>20.43</strong></td>
    <td><strong>18.53</strong></td>
    <td>71.95</td>
    <td><strong>20.75</strong></td>
    <td><strong>21.06</strong></td>
    <td><strong>19.67</strong></td>
    <td>71.63</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>focal</sub></td>
    <td>8.17</td>
    <td>7.03</td>
    <td>15.23</td>
    <td>72.24</td>
    <td>9.21</td>
    <td>8.12</td>
    <td>15.86</td>
    <td>71.81</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>any|focal</sub></td>
    <td>13.68</td>
    <td>13.83</td>
    <td>15.69</td>
    <td>72.29</td>
    <td>14.19</td>
    <td>14.26</td>
    <td>16.63</td>
    <td>71.72</td>
  </tr>
  <tr>
    <td><strong>MaxViT-S</strong></td>
    <td>J<sup>cb</sup><sub>bce</sub></td>
    <td>19.08</td>
    <td>18.53</td>
    <td><strong>19.72</strong></td>
    <td>72.85</td>
    <td>20.7</td>
    <td>19.78</td>
    <td><strong>21.26</strong></td>
    <td>72.3</td>
  </tr>
  <tr>
    <td>(68.2M)</td>
    <td>J<sup>cb</sup><sub>any|bce</sub></td>
    <td><strong>22.5</strong></td>
    <td><strong>23.99</strong></td>
    <td>19.17</td>
    <td>71.88</td>
    <td>23.95</td>
    <td>25.15</td>
    <td>20.76</td>
    <td>71.3</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>focal</sub></td>
    <td>17.41</td>
    <td>16.58</td>
    <td>18.28</td>
    <td><strong>73.48</strong></td>
    <td>18.96</td>
    <td>17.83</td>
    <td>20.32</td>
    <td><strong>72.52</strong></td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>any|focal</sub></td>
    <td>22.14</td>
    <td>23.22</td>
    <td>18.99</td>
    <td>71.98</td>
    <td><strong>24.46</strong></td>
    <td><strong>25.27</strong></td>
    <td>20.41</td>
    <td>71.51</td>
  </tr>
</tbody>
</table>

#### COCO Dataset
Performance metrics for COCO dataset.

<table>
<thead>
  <tr>
    <th rowspan="2">Model</th>
    <th rowspan="2">Loss</th>
    <th colspan="4"><strong>Validation</strong></th>
    <th colspan="4"><strong>Test</strong></th>
  </tr>
  <tr>
    <th>F1</th>
    <th>F2</th>
    <th>mAP</th>
    <th>F1-Neg</th>
    <th>F1</th>
    <th>F2</th>
    <th>mAP</th>
    <th>F1-Neg</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><strong>TresNet-L</strong></td>
    <td>J<sup>cb</sup><sub>bce</sub></td>
    <td>40.93</td>
    <td>36.41</td>
    <td>42.52</td>
    <td><strong>77.58</strong></td>
    <td>40.01</td>
    <td>35.68</td>
    <td>42.33</td>
    <td><strong>77.66</strong></td>
  </tr>
  <tr>
    <td>(53.6M)</td>
    <td>J<sup>cb</sup><sub>any|bce</sub></td>
    <td><strong>43.85</strong></td>
    <td><strong>41.59</strong></td>
    <td><strong>44.34</strong></td>
    <td>76.58</td>
    <td><strong>42.92</strong></td>
    <td><strong>40.81</strong></td>
    <td><strong>43.77</strong></td>
    <td>76.52</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>focal</sub></td>
    <td>35.35</td>
    <td>30.66</td>
    <td>38.29</td>
    <td>75.45</td>
    <td>35.12</td>
    <td>30.63</td>
    <td>38.09</td>
    <td>75.47</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>any|focal</sub></td>
    <td>40.91</td>
    <td>38.62</td>
    <td>40.29</td>
    <td>73.83</td>
    <td>39.45</td>
    <td>37.43</td>
    <td>39.54</td>
    <td>74.03</td>
  </tr>
  <tr>
    <td><strong>MaxViT-S</strong></td>
    <td>J<sup>cb</sup><sub>bce</sub></td>
    <td>38.52</td>
    <td>34.65</td>
    <td>40.56</td>
    <td>76.77</td>
    <td>37.88</td>
    <td>34.43</td>
    <td>40.24</td>
    <td>77.09</td>
  </tr>
  <tr>
    <td>(68.2M)</td>
    <td>J<sup>cb</sup><sub>any|bce</sub></td>
    <td>43.75</td>
    <td>42.71</td>
    <td>43.54</td>
    <td>76.33</td>
    <td>43.21</td>
    <td>42.25</td>
    <td>43.19</td>
    <td>76.24</td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>focal</sub></td>
    <td>43.46</td>
    <td>40.47</td>
    <td>44.8</td>
    <td><strong>79.62</strong></td>
    <td>43.14</td>
    <td>40.42</td>
    <td>44.82</td>
    <td><strong>79.75</strong></td>
  </tr>
  <tr>
    <td></td>
    <td>J<sup>cb</sup><sub>any|focal</sub></td>
    <td><strong>46.97</strong></td>
    <td><strong>46.85</strong></td>
    <td><strong>46.78</strong></td>
    <td>76.34</td>
    <td><strong>46.17</strong></td>
    <td><strong>45.97</strong></td>
    <td><strong>46.28</strong></td>
    <td>76.69</td>
  </tr>
</tbody>
</table>

## Pre-trained Models and Results

We provide a few pre-trained model weights and detailed results for reproducibility:

* **Pre-trained Model Weights**: [Download Link](https://drive.google.com/file/d/1KUs-zo5dG2D2kzj8tN7AhciQuU_H42FP/view?usp=sharing)
contains a few trained model weights
* **Experimental Results**: [Download Link](https://drive.google.com/file/d/1H3TCtLQA_wKek2ozv8u8OqZ4pN-B_h3p/view?usp=sharing) contains their validaiont/test predictions and results

**Using the Pre-trained Models:**

The version arguments for the scripts correspond to the folder structure in the downloaded weights:
* The `--versions` argument should be the tag that appears after `version_` in the folder name
* The `--log_dir` or `--score_dir` should point to the parent directory

**Example:**
* To run inference for weight folder named `nips_18209_weights/version_chest_tresnet_bce/`, use:
  * `--versions chest_tresnet_bce`
  * `--log_dir /path/to/nips_18209_weights/` (parent directory)

## Likelihood Simulation

The project includes simulation tool to visualize  the probability aggregation methods, likelihood and loss surfaces for two class scenario:

* **Location**: `likelihood_simulation/` directory
* **Components**:
  * `app.py`: A Streamlit application that provides an interactive visualization of likelihood surfaces

The simulation allows users to:
- Select labels for two classes (y₁, y₂)
- Adjust lambda parameter values
- Visualize probability surfaces, likelihood functions and loss landscapes
- Compare different approaches (power mean vs product)
- See how the novel auxiliary loss affects the overall loss landscape

To run the simulation:

```bash
streamlit likelihood_simulation/run app.py
```

This tool is particularly useful for understanding how the auxiliary loss term enhances class presence awareness in multi-label classification scenarios.

## Citation

If you find this work useful in your research, please consider citing:

```bibtex
@article{yourname2024gmean,
  title={Any-Class Presence Likelihood for Robust Multi-Label Classification with Abundant Negative Data},
  author={Tissera, Dumindu and Awadallah, Omar and Danish, Muhammad Umair and Sadhu, Ayan and Grolinger, Katarina},
  journal={arXiv preprint arXiv:2506.05721},
  year={2025}
}
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageChops\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these at the very top of your script or notebook cell, before any other imports\n",
    "os.environ[\"HF_HOME\"] = \"/mnt/datassd0/chest-xray/huggingface\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/mnt/datassd0/chest-xray/huggingface_cache\"\n",
    "os.environ[\"TMPDIR\"] = \"/mnt/datassd0/chest-xray/tmp\"  # Also redirect temporary files if needed\n",
    "os.makedirs(os.environ[\"HF_DATASETS_CACHE\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"TMPDIR\"], exist_ok=True)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"/mnt/datassd0/chest-xray/NIH-Chest-X-ray-dataset.py\",\n",
    "    name=\"image-classification\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=\"/mnt/datassd0/chest-xray/huggingface_cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print available splits and dataset info\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "if \"labels\" in train_dataset.features:\n",
    "    feature = train_dataset.features[\"labels\"]\n",
    "    if hasattr(feature, \"feature\") and hasattr(feature.feature, \"names\"):\n",
    "        label_names = feature.feature.names\n",
    "\n",
    "# Create a 3x3 grid of subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 15))\n",
    "\n",
    "for ax in axes.flat:\n",
    "    # Pick a random sample from the dataset\n",
    "    idx = random.randint(0, len(train_dataset) - 1)\n",
    "    sample = train_dataset[idx]\n",
    "    \n",
    "    # Get the image and its labels (as a list)\n",
    "    image = sample[\"image\"]\n",
    "    numeric_labels = sample[\"labels\"]\n",
    "    \n",
    "    # Convert numeric labels to human-readable names if mapping exists\n",
    "    if label_names:\n",
    "        labels_text = [label_names[label] for label in numeric_labels]\n",
    "    else:\n",
    "        labels_text = numeric_labels\n",
    "        \n",
    "    label_str = \", \".join(labels_text)\n",
    "    \n",
    "    # Display the image and set its title to the label names\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f\"Label: {label_str}\", fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all labels from the dataset\n",
    "if label_names:\n",
    "    all_labels = [label_names[label] for label in itertools.chain.from_iterable(train_dataset[\"labels\"])]\n",
    "else:\n",
    "    all_labels = list(itertools.chain.from_iterable(train_dataset[\"labels\"]))\n",
    "\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "# Sort the label counts in decreasing order\n",
    "sorted_counts = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "labels_sorted, counts_sorted = zip(*sorted_counts)\n",
    "\n",
    "# Create explicit x-axis positions\n",
    "x_positions = np.arange(len(labels_sorted))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x_positions, counts_sorted, align='center')\n",
    "plt.xticks(x_positions, labels_sorted, rotation=45)\n",
    "plt.title(\"Label Distribution in NIH Chest X-ray Dataset (Decreasing Order)\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function that classifies each sample in a batch\n",
    "def classify_finding(batch):\n",
    "    groups = []\n",
    "    for lab_list in batch[\"labels\"]:\n",
    "        # If the sample's labels is exactly [0], count it as \"No Finding\"\n",
    "        if len(lab_list) == 1 and lab_list[0] == 0:\n",
    "            groups.append(\"No Finding\")\n",
    "        else:\n",
    "            groups.append(\"Finding\")\n",
    "    return {\"finding_group\": groups}\n",
    "\n",
    "# Use the dataset's map function with batching and multiple processes\n",
    "train_dataset = train_dataset.map(\n",
    "    classify_finding, \n",
    "    batched=True, \n",
    "    batch_size=1000,  # adjust as needed for your hardware\n",
    "    num_proc=4        # adjust according to available CPU cores\n",
    ")\n",
    "\n",
    "# Count the occurrences in the new \"finding_group\" column\n",
    "group_counts = Counter(train_dataset[\"finding_group\"])\n",
    "print(group_counts)\n",
    "\n",
    "# Plot a bar chart for \"No Finding\" vs \"Finding\"\n",
    "labels_plot = list(group_counts.keys())\n",
    "counts_plot = [group_counts[label] for label in labels_plot]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(labels_plot, counts_plot, color=[\"green\", \"red\"])\n",
    "plt.title(\"No Finding vs. Finding\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'train_dataset[\"labels\"]' is a list of lists and 'label_names' exists.\n",
    "labels_list = train_dataset[\"labels\"]\n",
    "num_samples = len(labels_list)\n",
    "num_classes = len(label_names)  # since label_names is provided\n",
    "\n",
    "# Create a binary matrix X: shape (num_samples, num_classes)\n",
    "X = np.zeros((num_samples, num_classes), dtype=int)\n",
    "for i, lab_list in enumerate(labels_list):\n",
    "    # For each sample, mark the labels as 1\n",
    "    X[i, lab_list] = 1\n",
    "\n",
    "# Compute the co-occurrence matrix: X^T dot X gives a (num_classes x num_classes) matrix\n",
    "co_matrix = np.dot(X.T, X)\n",
    "\n",
    "# Remove self-co-occurrence by setting diagonal to 0\n",
    "np.fill_diagonal(co_matrix, 0)\n",
    "\n",
    "# Create a DataFrame with proper index and columns using label_names\n",
    "co_occurrence_df = pd.DataFrame(co_matrix, index=label_names, columns=label_names)\n",
    "\n",
    "# Plot the heatmap using seaborn\n",
    "plt.figure(figsize=(15, 10))\n",
    "ax = sns.heatmap(co_occurrence_df, cmap='Blues', annot=True, fmt=\"d\")\n",
    "ax.set_xticklabels(co_occurrence_df.columns, rotation=90, fontsize=8)\n",
    "ax.set_yticklabels(co_occurrence_df.index, rotation=0, fontsize=8)\n",
    "plt.title(\"Label Co-occurrence Heatmap in NIH Chest X-ray Dataset\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fast function to check image mode\n",
    "def detect_grayscale(example):\n",
    "    # The mode attribute is already available in the PIL image.\n",
    "    # This function just returns True if the mode is \"L\" or \"1\".\n",
    "    return {\"is_gray\": example[\"image\"].mode in (\"L\")}\n",
    "\n",
    "# Process the dataset in parallel (adjust num_proc based on available CPU cores)\n",
    "train_dataset = train_dataset.map(detect_grayscale, num_proc=4)\n",
    "\n",
    "# Count the results\n",
    "gray_count = sum(train_dataset[\"is_gray\"])\n",
    "color_count = len(train_dataset) - gray_count\n",
    "\n",
    "print(f\"Grayscale images: {gray_count}\")\n",
    "print(f\"Color images: {color_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example threshold: if the centroid is more than 10% of the maximum offset away from the center, consider it distorted.\n",
    "DISTORTION_THRESHOLD = 0.5\n",
    "\n",
    "def detect_distortion(example, threshold_ratio=DISTORTION_THRESHOLD):\n",
    "    # Convert image (a PIL.Image) to grayscale numpy array.\n",
    "    img = np.array(example[\"image\"].convert(\"L\"))\n",
    "    \n",
    "    # Apply Otsu's thresholding to segment the image.\n",
    "    # This yields a binary image where (typically) the x-ray content is white.\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find indices of white pixels (foreground)\n",
    "    indices = np.argwhere(binary == 255)\n",
    "    \n",
    "    # If no foreground is detected, we can assume no significant content (or skip marking as distorted)\n",
    "    if len(indices) == 0:\n",
    "        distorted = False\n",
    "    else:\n",
    "        # Compute the centroid (row, col) of the foreground pixels.\n",
    "        centroid = indices.mean(axis=0)\n",
    "        h, w = img.shape\n",
    "        center = np.array([h / 2, w / 2])\n",
    "        offset = np.linalg.norm(centroid - center)\n",
    "        \n",
    "        # Maximum possible offset is half the diagonal of the image.\n",
    "        max_offset = np.sqrt((h / 2) ** 2 + (w / 2) ** 2)\n",
    "        normalized_offset = offset / max_offset\n",
    "        \n",
    "        distorted = normalized_offset > threshold_ratio\n",
    "    \n",
    "    # Add the result to the example.\n",
    "    example[\"distorted\"] = distorted\n",
    "    return example\n",
    "\n",
    "# Process the dataset in batches with multiple processes for efficiency.\n",
    "train_dataset = train_dataset.map(detect_distortion, batched=False, num_proc=4)\n",
    "\n",
    "# Count how many images are marked as distorted.\n",
    "total_images = len(train_dataset)\n",
    "distorted_count = sum(train_dataset[\"distorted\"])\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"Distorted images: {distorted_count}\")\n",
    "\n",
    "# # Get a few random distorted images.\n",
    "# distorted_samples = [sample for sample in train_dataset if sample[\"distorted\"]]\n",
    "# non_distorted_samples = [sample for sample in train_dataset if not sample[\"distorted\"]]\n",
    "\n",
    "# print(\"Displaying some distorted images:\")\n",
    "# for sample in random.sample(distorted_samples, min(4, len(distorted_samples))):\n",
    "#     plt.figure(figsize=(4, 4))\n",
    "#     plt.imshow(sample[\"image\"])\n",
    "#     plt.title(\"Distorted\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# print(\"Displaying some non-distorted images:\")\n",
    "# for sample in random.sample(non_distorted_samples, min(4, len(non_distorted_samples))):\n",
    "#     plt.figure(figsize=(4, 4))\n",
    "#     plt.imshow(sample[\"image\"])\n",
    "#     plt.title(\"Centered\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
